# FILE: flaskAPI/alert.py
# VERSION: 2.1 - Patched Knowledge-First Dispatcher
import os
import json
import logging
import re
import requests
import yaml
import sys
from flask import Flask, request, jsonify
from datetime import datetime
from waitress import serve
from functools import lru_cache

# Import c√°c h√†m t·ª´ c√°c file kh√°c
try:
    from elk import get_logs_for_instance
except ImportError:
    def get_logs_for_instance(*args, **kwargs):
        logging.warning("elk.py not found, returning empty log string.")
        return "Could not retrieve logs from ELK."

# --- C·∫§U H√åNH T·ª™ BI·∫æN M√îI TR∆Ø·ªú·ªúNG ---
LOG_LEVEL = os.getenv("LOG_LEVEL", "INFO").upper()
# FIX 3: Ch·∫•p nh·∫≠n c·∫£ bi·∫øn c≈© v√† bi·∫øn m·ªõi ƒë·ªÉ tƒÉng t√≠nh t∆∞∆°ng th√≠ch
RAG_API_URL = os.getenv("RAG_API_URL", os.getenv("RAG_ENGINE_URL")) 
SRE_AGENT_URL = os.getenv("SRE_AGENT_URL", "http://sre-agent:5002")
ALERTMANAGER_URL = os.getenv("ALERTMANAGER_URL", "http://192.168.111.111:9093/api/v1/alerts")
KNOWLEDGE_SOURCE_DIR = os.getenv("KNOWLEDGE_SOURCE_DIR", "/rag_source")

# --- THI·∫æT L·∫¨P LOGGING ---
logger = logging.getLogger('alert-api')
logger.setLevel(LOG_LEVEL)
if not logger.handlers:
    handler = logging.StreamHandler(sys.stdout)
    formatter = logging.Formatter('%(asctime)s - [ALERT-API] - [%(levelname)s] - %(message)s')
    handler.setFormatter(formatter)
    logger.addHandler(handler)
logger.propagate = False
logging.getLogger('urllib3').setLevel(logging.WARNING)

app = Flask(__name__)

# --- C√ÅC H√ÄM HELPER & LOGIC C·ªêT L√ïI ---

@lru_cache(maxsize=128)
def find_knowledge_yaml_by_host(host_key: str):
    """
    T√¨m ki·∫øm file YML d·ª±a tr√™n host_key (c√≥ th·ªÉ l√† hostname ho·∫∑c IP).
    FIX 1: ƒê√£ th√™m logic so kh·ªõp c·∫£ IP v√† hostname.
    Tr·∫£ v·ªÅ (filepath, yaml_doc, matched_host_dict)
    """
    if not os.path.exists(KNOWLEDGE_SOURCE_DIR):
        logger.error(f"Th∆∞ m·ª•c tri th·ª©c '{KNOWLEDGE_SOURCE_DIR}' kh√¥ng t·ªìn t·∫°i.")
        return None, None, None
    try:
        for filename in os.listdir(KNOWLEDGE_SOURCE_DIR):
            if filename.endswith((".yml", ".yaml")):
                filepath = os.path.join(KNOWLEDGE_SOURCE_DIR, filename)
                with open(filepath, 'r', encoding='utf-8') as f:
                    doc = yaml.safe_load(f)
                    hosts = doc.get('metadata', {}).get('hosts', [])
                    if isinstance(hosts, list):
                        for host in hosts:
                            # So kh·ªõp c·∫£ hostname v√† ip
                            if isinstance(host, dict) and host_key in (host.get('hostname'), host.get('ip')):
                                logger.info(f"T√¨m th·∫•y file tri th·ª©c '{filename}' cho host '{host_key}'.")
                                return filepath, doc, host
    except Exception as e:
        logger.error(f"L·ªói khi qu√©t kho tri th·ª©c: {e}")
    return None, None, None

def get_current_metrics_summary(instance_ip: str, initial_data: dict) -> str:
    """T·∫°o m·ªôt b·∫£n t√≥m t·∫Øt metric t·ª´ d·ªØ li·ªáu ban ƒë·∫ßu."""
    metric = initial_data.get('metric')
    if metric:
        return f"- Metric Trigger: {metric}\n- Current Value: {initial_data.get('value')}\n- Predicted Value: {initial_data.get('predicted_value')}"
    return "N/A (C·∫£nh b√°o ƒë∆∞·ª£c k√≠ch ho·∫°t b·ªüi log)"

def call_llm_for_analysis(prompt: str, incident_id: str) -> str:
    """H√†m chuy√™n d·ª•ng ƒë·ªÉ g·ªçi LLM v√† ch·ªâ l·∫•y v·ªÅ c√¢u tr·∫£ l·ªùi."""
    if not RAG_API_URL:
        logger.warning(f"[{incident_id}] RAG_API_URL/RAG_ENGINE_URL is not set. Cannot get AI analysis.")
        return "AI analysis is unavailable due to configuration error."
    try:
        logger.info(f"[{incident_id}] Sending analysis prompt to RAG API.")
        response = requests.post(RAG_API_URL, json={"message": prompt}, timeout=120)
        response.raise_for_status()
        reply = response.json().get("reply", "No reply content from AI.")
        logger.info(f"[{incident_id}] Received analysis from AI.")
        return reply
    except requests.RequestException as e:
        logger.error(f"[{incident_id}] Failed to call RAG API: {e}")
        return f"AI analysis failed due to connection error: {e}"

def dispatch_automated_action(playbook: dict, target_host_ip: str, host_alias: str, incident_id: str):
    """
    G·ª≠i m·ªôt h√†nh ƒë·ªông t·ª± ƒë·ªông c·ª• th·ªÉ ƒë·∫øn SRE Agent.
    FIX 2: ƒê√£ s·ª≠ d·ª•ng host_alias cho playbook v√† th√™m placeholder {{TARGET_IP}}.
    """
    if not SRE_AGENT_URL:
        logger.warning(f"[{incident_id}] SRE_AGENT_URL is not set. Skipping automation.")
        return None

    command_template = playbook.get("target")
    if not command_template:
        logger.error(f"[{incident_id}] Playbook '{playbook.get('name')}' is missing 'target' command.")
        return None

    # Thay th·∫ø c·∫£ 2 placeholder ƒë·ªÉ YAML linh ho·∫°t h∆°n
    final_command = (command_template
                     .replace("{{TARGET_HOST}}", host_alias)
                     .replace("{{TARGET_IP}}", target_host_ip))

    logger.warning(f"[{incident_id}] DISPATCHING AUTOMATION: '{playbook.get('name')}' on host '{target_host_ip}'. Command: '{final_command}'")
    payload = {"command": final_command, "target_host": host_alias} # G·ª≠i host_alias ƒë·ªÉ logging trong SRE Agent

    try:
        response = requests.post(f"{SRE_AGENT_URL}/execute", json=payload, timeout=180)
        response.raise_for_status()
        return response.json()
    except requests.RequestException as e:
        logger.error(f"[{incident_id}] Failed to dispatch command to SRE Agent: {e}")
        return {"status": "ERROR", "output": f"Failed to contact SRE Agent: {e}"}

def format_final_alert(incident: dict):
    # (H√†m n√†y kh√¥ng thay ƒë·ªïi)
    instance = incident['instance']
    severity = incident['severity']
    analysis = incident['analysis']
    action_plan = incident['action_plan']
    execution_result = incident['execution_result']
    knowledge_source = incident['knowledge_source']

    summary = f"[{severity.upper()}] {analysis.get('title', 'AI-Driven Alert')} on {instance} (Source: {os.path.basename(knowledge_source) if knowledge_source != 'AI Fallback' else knowledge_source})"
    
    description_parts = [
        f"üîé **Ch·∫©n ƒëo√°n t·ª´ AI:** {analysis.get('summary', 'N/A')}",
        f"üñ• **Host:** {instance}",
        f"üìù **Ngu·ªìn tri th·ª©c:** {os.path.basename(knowledge_source) if knowledge_source != 'AI Fallback' else knowledge_source}",
    ]
    if execution_result:
        description_parts.append("\n--- **H√†nh ƒë·ªông t·ª± ƒë·ªông** ---")
        status = execution_result.get("status", "UNKNOWN")
        output = execution_result.get('output', 'No output.')
        description_parts.append(f"‚úÖ **Tr·∫°ng th√°i:** {status}")
        description_parts.append(f"üìã **K·∫øt qu·∫£:**\n```\n{output[:500]}\n```")

    manual_steps = action_plan.get('investigation_steps', []) + [p for p in action_plan.get('remediation_playbooks', []) if not p.get('allow_automation')]
    if manual_steps:
        description_parts.append("\n--- **G·ª£i √Ω c√°c b∆∞·ªõc th·ªß c√¥ng** ---")
        for step in manual_steps:
            description_parts.append(f"- **{step.get('name')}**: `{step.get('command') or step.get('target')}`")

    return {
        "labels": { "alertname": f"AIOps_{analysis.get('system_code', 'General')}", "instance": instance, "severity": severity.lower(), "source": "AI_SRE_Platform" },
        "annotations": { "summary": summary, "description": "\n".join(description_parts) }
    }


def process_incident(initial_data: dict, incident_id: str):
    instance_ip = initial_data.get("instance", "unknown").split(":")[0]
    event_time = datetime.fromtimestamp(initial_data.get('timestamp', int(datetime.now().timestamp())))
    
    logger.info(f"[{incident_id}] Enriching data for instance '{instance_ip}'.")
    metrics_summary = get_current_metrics_summary(instance_ip, initial_data)
    logs_summary = get_logs_for_instance(instance_ip, around_time=event_time, window_minutes=5)
    
    incident = { "id": incident_id, "instance": instance_ip, "severity": initial_data.get("severity", "warning"), "initial_alert": initial_data, "metrics": metrics_summary, "logs": logs_summary, "knowledge_source": "AI Fallback", "action_plan": {}, "analysis": {}, "execution_result": None }

    # FIX 1 (S·ª≠ d·ª•ng): T√¨m ki·∫øm v√† nh·∫≠n v·ªÅ 3 gi√° tr·ªã
    filepath, doc, matched_host = find_knowledge_yaml_by_host(instance_ip)

    if doc and matched_host:
        logger.info(f"[{incident_id}] Found knowledge YAML. Processing with 'YAML-First' strategy.")
        incident['knowledge_source'] = filepath
        incident['action_plan'] = doc.get('actionable_plan', {})
        metadata = doc.get('metadata', {})
        
        prompt = f"""B·∫°n l√† m·ªôt k·ªπ s∆∞ SRE. M·ªôt s·ª± c·ªë ƒë√£ x·∫£y ra tr√™n host {instance_ip}. 
D∆∞·ªõi ƒë√¢y l√† tri th·ª©c ƒë√£ ƒë∆∞·ª£c ki·ªÉm duy·ªát v√† d·ªØ li·ªáu s·ª± c·ªë th·ª±c t·∫ø. H√£y ƒë·ªçc v√† ƒë∆∞a ra m·ªôt b·∫£n t√≥m t·∫Øt ch·∫©n ƒëo√°n ng·∫Øn g·ªçn.

**TRI TH·ª®C C√ì S·∫¥N (T·ª´ file {os.path.basename(filepath)}):**
---
{doc.get('content', 'Kh√¥ng c√≥ n·ªôi dung m√¥ t·∫£.')}
---
**D·ªÆ LI·ªÜU S·ª∞ C·ªê TH·ª∞C T·∫æ:**
---
- **Metrics:** {metrics_summary}
- **Logs:** {logs_summary or 'Kh√¥ng c√≥ log b·∫•t th∆∞·ªùng n√†o ƒë∆∞·ª£c t√¨m th·∫•y.'}
---
**Y√äU C·∫¶U:** ƒê∆∞a ra m·ªôt c√¢u ch·∫©n ƒëo√°n ng·∫Øn g·ªçn (1-2 c√¢u).
"""
        incident['analysis']['summary'] = call_llm_for_analysis(prompt, incident_id)
        incident['analysis']['title'] = metadata.get('title', 'Incident Analysis')
        incident['analysis']['system_code'] = metadata.get('system_code', 'UNKNOWN')

        # FIX 2 (S·ª≠ d·ª•ng): Th·ª±c thi h√†nh ƒë·ªông v·ªõi alias ch√≠nh x√°c
        host_alias_for_ansible = matched_host.get('hostname', instance_ip)
        for playbook in incident['action_plan'].get('remediation_playbooks', []):
            if playbook.get("allow_automation") is True:
                incident['execution_result'] = dispatch_automated_action(playbook, instance_ip, host_alias_for_ansible, incident_id)
                break
    else:
        logger.info(f"[{incident_id}] No specific YAML found. Using RAG fallback strategy.")
        prompt = f"Ph√¢n t√≠ch s·ª± c·ªë sau tr√™n host {instance_ip} v√† ƒë·ªÅ xu·∫•t gi·∫£i ph√°p...\n**D·ªØ li·ªáu s·ª± c·ªë:**\n- Initial Alert: {json.dumps(incident['initial_alert'])}\n- Relevant Metrics: {incident['metrics']}\n- Relevant Logs: {incident['logs'] or 'Kh√¥ng c√≥ log b·∫•t th∆∞·ªùng.'}\nH√£y tr·∫£ l·ªùi v·ªõi m·ªôt ch·∫©n ƒëo√°n ng·∫Øn g·ªçn."
        ai_response = call_llm_for_analysis(prompt, incident_id)
        incident['analysis']['summary'] = ai_response
        incident['analysis']['title'] = f"AI Analysis for {instance_ip}"
        incident['analysis']['system_code'] = "General"
        incident['action_plan'] = {"remediation_playbooks": []}

    final_alert_payload = format_final_alert(incident)
    logger.info(f"[{incident_id}] Final alert created. Summary: {final_alert_payload['annotations']['summary']}")
    try:
        with open(os.path.join("ai_suggestions", f"{incident_id}.md"), "w", encoding='utf-8') as f:
            f.write(f"# {final_alert_payload['annotations']['summary']}\n\n{final_alert_payload['annotations']['description']}")
    except Exception as e:
        logger.error(f"[{incident_id}] Could not write debug markdown file: {e}")

    if ALERTMANAGER_URL:
        try:
            res = requests.post(ALERTMANAGER_URL, json=[final_alert_payload], timeout=15)
            res.raise_for_status()
            logger.info(f"[{incident_id}] Successfully sent alert to Alertmanager.")
        except requests.RequestException as e:
            logger.error(f"[{incident_id}] Failed to send alert to Alertmanager: {e}")
            
    return incident


@app.route("/alert", methods=["POST"])
def alert_endpoint():
    data = request.get_json()
    if not data or "instance" not in data:
        return jsonify({"status": "error", "message": "Invalid JSON or missing 'instance'"}), 400

    instance_ip = data.get("instance", "unknown").split(":")[0]
    incident_id = f"{datetime.now().strftime('%y%m%d_%H%M%S')}_{instance_ip.replace('.', '_')}"
    
    logger.info(f"[{incident_id}] === New Incident Received for instance '{instance_ip}' ===")
    
    result = process_incident(data, incident_id)
    
    return jsonify({"status": "processed", "incident_id": incident_id, "knowledge_source": result['knowledge_source']})

if __name__ == '__main__':
    logger.info("üöÄ AI SRE Alerting Service (v2.1 - Patched) is ready.")
    logger.info(f"Knowledge Source Directory: {KNOWLEDGE_SOURCE_DIR}")
    if not RAG_API_URL:
        logger.error("FATAL: RAG_API_URL or RAG_ENGINE_URL environment variable is not set!")
    else:
        logger.info(f"RAG API URL: {RAG_API_URL}")

    serve(app, host='0.0.0.0', port=5001, threads=10)
